---
title: "Gene name errors and Excel: a symptom of sloppy genomic data analysis or software flaw?"
author: "Mark Ziemann and Mandhri Abeysooriya"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
  html_document:
    toc: true
    toc_float: true
    fig_width: 7
    fig_height: 5
theme: cosmo
---

Autocorrection, or predictive text is a common feature of many modern tech tools from internet searches, messaging apps to word processors and spreadsheets. Autocorrection is a blessing for those of us with bad spelling or clumsy typing but when the predictive text algorithm gets it wrong, it can change the message in dramatic and sometimes hilarious ways (link). Spreadsheets for example apply predictive text to guess what type of data the user wants. If you type a phone number starting with zero into a cell, the software will recognise it as a numeric value and remove the leading zero. If you type “=8/2”, the result will appear as “4”, but if you type “8/2” it will be recognised as a date. Hexadecimal numbers commonly used in computer science containing an “E” such as 1E9 (decimal=489) get converted to scientific notation (1 to the power of 9). If used to analyse scientific data, the simple act of opening a data file with Excel with the default settings can lead to corruption due to autocorrection.

In the field of genetics, it was recognised way back in [2004](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-5-80) that about 30 human gene and protein names were susceptible to conversion to dates when typed, pasted or imported into an Excel spreadsheet. This is easy to imagine because they have names like MARCH1, SEPT1, Oct-4, jun, etc. After we spotted this error in supplementary data files attached to a high impact journal article, we became interested in how widespread these errors are in scientific publications. In 2016 we [reported](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7) a screen of 18 leading genomics journals, finding ~20% of articles with supplementary Excel gene lists had similar errors. This suggested to us that researchers and journals were largely unaware of the autocorrect problem and how to avoid it. As a result, the Human Gene Name Consortium, the official body responsible for naming human genes, renamed the most problematic genes to avoid spreadsheet autocorrection. For example MARCH1 and SEPT1 were changed to MARCHF1 and SEPTIN1 respectively.

![Example list of gene names in Excel](https://github.com/markziemann/GeneNameErrors2020/blob/master/images/image1.png?raw=true "Example list of gene names in Excel")

Earlier this year we repeated our analysis, expanding it to cover a wider selection of open access journals, anticipating that researchers and journals would be taking steps to prevent such errors appearing in their supplementary data files. We were shocked to find in the period 2014 to 2020 there were 3436 articles containing gene name errors (~31% of our sample), indicating the problem had not gone away at all but was apparently getting worse (link). Indeed the number of affected articles continues to increase every year.

![Gene name errors still on the rise. Data Source: Abeysooriya et al 2021](https://github.com/markziemann/GeneNameErrors2020/blob/master/images/image2.png?raw=true "Gene name errors still on the rise.")

There is an argument that these errors don’t really matter because it only affects about 30 genes (out of 44k in the genome), and is unlikely to overturn the conclusions of any particular genomic study. Anyone reusing these supplementary data files will find this small set of genes missing or corrupted; irritating if your research project examines the SEPT gene family but it's just one of many gene families in existence.

Still it matters because it raises the question as to how these errors can sneak into scientific publications, which gets to the heart of public trust in research. If gene name autocorrect errors can pass peer-review undetected into published data files, then what other errors might be lurking among the thousands of data points?

In the field of business and finance, there are many examples of where spreadsheet errors led to costly and embarrassing [losses](http://www.eusprig.org/horror-stories.htm). For example in 2012 JP Morgan declared a loss of more than $6 billion thanks to a series of trading blunders made possible by formula errors in its modeling spreadsheets. Analysis of thousands of spreadsheets at Enron Corporation show that [errors were rife](https://ieeexplore.ieee.org/document/7202944) and suggest over-reliance on spreadsheets contributed to the company's downfall. A now infamous article by Reinhart and Rogoff was used to justify austerity cuts in the aftermath of the global financial crisis but the analysis contained a [critical Excel error](https://theconversation.com/the-reinhart-rogoff-error-or-how-not-to-excel-at-economics-13646) that led to omitting 5 of the 20 countries in their modeling.

Just last year, a [spreadsheet error at Public Health England](https://www.bbc.com/news/technology-54423988) led to the loss of data corresponding to ~15,000 positive COVID-19 cases, compromising contact tracing efforts for 8 days (25 Sept to 2 Oct) while case numbers were rapidly growing. Missing data was eventually tracked down to a limitation of an older Excel file format limited to only 65,000 rows while the number of cases grew well beyond this. In the healthcare setting, clinical data entry errors into spreadsheets can be as high as 5%, while a separate study of hospital administration spreadsheets showed 11/12 contained critical flaws. 

In biomedical research, a [mistake](https://www.nature.com/articles/nm0610-618a) in preparing a sample sheet resulted in a whole set of sample labels being shifted by one position and completely changing the genomic analysis results. These results were significant because they were being used to justify the drugs patients were to receive in a subsequent clinical trial. This may be an isolated case, but we don’t really know how common such errors are in research because of a lack of systematic error-finding studies.

Spreadsheets are ubiquitous in schools, businesses and government departments, and are wonderfully versatile for data entry, calculations and making graphs. But spreadsheets have their limitations. Most businesses prefer specialised accounting software over spreadsheets because they are more structured and easier to audit. In IT, large datasets are managed in databases such as SQL, which are more robust and capable than Excel. Since scientific journal articles went from print to online, scientists have used Excel sheets to share their supplementary data files, but as science becomes more data-intensive and the limitations of Excel are becoming more apparent, is it time for researchers to give Excel the boot?

In genomics and other data intensive sciences, scripted computer languages like python and R are proving useful in the analysis of big data sets. They offer benefits including enhanced analytical techniques, reproducibility, auditability and better management of code versions and contributions from different individuals. The dream of end-to-end analytical reproducibility underlying scientific works is becoming realised in a way that would be impossible with point-and-click tools like spreadsheets. And although the learning curve is nearly vertical, the benefits to better science are worth it in the long haul. 

To answer the question whether gene name errors are a symptom of sloppy work or software flaw, we must recognise that Excel is suited to small-scale data entry and lightweight analysis. Microsoft states that Excel’s defaults are designed to satisfy the needs of most users most of the time. Clearly, genomic science does not represent a common use case. Any dataset larger than 100 rows is just not suitable for a spreadsheet. Initiatives like [Software Carpentry](https://software-carpentry.org/about/) are helping, by offering computing skills workshops to researchers, but there needs to be a greater focus on giving undergraduate life scientists the advanced analytical skills to participate and succeed in the data-driven workplace of the future. 